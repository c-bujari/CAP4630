{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMiMi2VYdmyz499qcpJWgdo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c-bujari/CAP4630/blob/master/HW_3/HW_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8opIlCVzPbV",
        "colab_type": "text"
      },
      "source": [
        "#Homework Assignment 3\n",
        "###CAP 4630 Artificial Intelligience\n",
        "####Clyde Bujari"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbgx6z55zcTK",
        "colab_type": "text"
      },
      "source": [
        "## Problem 1\n",
        "Implement the function get_random_data(w, b, mu, sigma, m) that generates random data for logisitic regression with two features, x_1 and x_2. This function should return the array data of shape (m, 2) and the array labels of shape (m, 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vyo2ft0nAwlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b7XI765zt2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## w, b, mu, sigma are constants for statistics stuff\n",
        "## m is the number of rows of data you want.\n",
        "def get_random_data(w, b, mu, sigma, m):\n",
        "\n",
        "  ## Class labels for each entry should be either 0 or 1 \n",
        "  labels = np.random.randint(2, size=(m, 1))\n",
        "\n",
        "  ## Generate the data array\n",
        "  ## In order to create an array of the correct shape, I assigned random values to both\n",
        "  ## x_1 and x_2. This is, however, less inefficient than adding new entries to the array,\n",
        "  ## as numpy would be reallocating the memory for the array each time.\n",
        "  data = np.random.rand(m, 2)\n",
        "\n",
        "  ## Create an np array of samples from the normal distribution with mean mu and sd sigma\n",
        "  samples = np.random.default_rng().normal(mu, sigma, 1000)\n",
        "\n",
        "  ## Second feature x_2 = w * x_1 + b + (-1)^c * n\n",
        "  for data_row, label_row, n, in zip(data, labels, samples):\n",
        "    ## For some reason, python thinks that -1^c ALWAYS = -1, so I am using an if statement instead.\n",
        "    ## Original statment: data_row[1] = w * data_row[0] + b + (-1**label_row[0]) * n\n",
        "    if(label_row[0]):\n",
        "      data_row[1] = w * data_row[0] + b + -1 * n\n",
        "    else:\n",
        "      data_row[1] = w * data_row[0] + b + n\n",
        "\n",
        "  return labels, data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cg-WImj1MgZ",
        "colab_type": "text"
      },
      "source": [
        "Implement the function display_random_data that takes as input the above two arrays labels and data. It should create scatter plot of the 2D points stored in data. Use red dots to plot the points whose labels are 1 and blue dots to plot the points whose labels are 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaDBtXYh1kj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display_random_data(labels, data):\n",
        "  for l, d in zip(labels, data):\n",
        "    if(l):\n",
        "      plt.plot(d[0], d[1], \"r.\")\n",
        "    else:\n",
        "      plt.plot(d[0], d[1], \"b.\")\n",
        "\n",
        "  plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "  plt.ylabel(\"$x_2$\", rotation=0, fontsize=18)\n",
        "  plt.axis([0, 1, -15, 15])\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0WUMsRMcqJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Constants used to call get_random_data\n",
        "w = 10\n",
        "b = -5\n",
        "mu = 3\n",
        "sigma = 1\n",
        "m = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgjW3SvG6Jtk",
        "colab_type": "code",
        "outputId": "45a78377-4d93-4102-e702-f268896d378a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "## Generate random data\n",
        "labels, data = get_random_data(w, b, mu, sigma, m)\n",
        "\n",
        "## Display scatter plot\n",
        "display_random_data(labels, data)"
      ],
      "execution_count": 825,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAESCAYAAAAFYll6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5U8s-Gp1XQ0",
        "colab_type": "text"
      },
      "source": [
        "Split the data/labels into a training set (80%) and a test set (20%)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_3d-p6GWctO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Scikit-learn includes a handy function to do this automatically\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## Split the data generated into a training set (80%) and a test set (20%)\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, train_size = 0.8, test_size = 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRfGK4gxSmke",
        "colab_type": "text"
      },
      "source": [
        "##Problem 2\n",
        "Create a Keras to implement logistic regression with two features and train it with the data generated in Problem 1. The loss should be the binary cross entropy loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pxkz1s1eSqEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFDpZhNhuRR6",
        "colab_type": "text"
      },
      "source": [
        "Initalize the model, using binary cross entropy as the loss function as directed in instructions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbocZtCa0_eU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "network = models.Sequential()\n",
        "\n",
        "## As discussed in lecture + in lecture videos, relu performs better than sigmoid\n",
        "network.add(layers.Dense(train_labels.shape[1],\n",
        "                  activation='relu',\n",
        "                  input_dim=(train_data.shape[1])))\n",
        "\n",
        "network.compile(loss='binary_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clFkkbCPErzB",
        "colab_type": "text"
      },
      "source": [
        "Train the model. I chose to train for 20 epochs, anything more is unnecessary or overfits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHWU5zuiCSVK",
        "colab_type": "code",
        "outputId": "cad3d747-7a9d-4713-bccb-6644578986b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        }
      },
      "source": [
        "network.fit(train_data, train_labels, epochs=20, batch_size = 8, validation_data=(test_data,test_labels), verbose=1)"
      ],
      "execution_count": 829,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 10.2494 - accuracy: 0.2875 - val_loss: 11.0823 - val_accuracy: 0.1500\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 10.2459 - accuracy: 0.3000 - val_loss: 11.0819 - val_accuracy: 0.1500\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 10.2446 - accuracy: 0.3000 - val_loss: 11.0821 - val_accuracy: 0.1500\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 10.2433 - accuracy: 0.3000 - val_loss: 11.0818 - val_accuracy: 0.1500\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 10.2425 - accuracy: 0.3000 - val_loss: 11.0815 - val_accuracy: 0.1500\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 10.2412 - accuracy: 0.3000 - val_loss: 11.0813 - val_accuracy: 0.1500\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 10.2418 - accuracy: 0.3000 - val_loss: 11.0813 - val_accuracy: 0.1500\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.8951 - accuracy: 0.3250 - val_loss: 8.1303 - val_accuracy: 0.2500\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.3165 - accuracy: 0.4875 - val_loss: 0.1058 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.5509 - accuracy: 0.8500 - val_loss: 0.1665 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.3024 - accuracy: 0.8750 - val_loss: 0.2068 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2938 - accuracy: 0.8875 - val_loss: 0.1655 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2883 - accuracy: 0.8750 - val_loss: 0.1827 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2814 - accuracy: 0.8875 - val_loss: 0.2092 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2845 - accuracy: 0.8875 - val_loss: 0.2322 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2736 - accuracy: 0.9000 - val_loss: 0.1379 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2731 - accuracy: 0.8625 - val_loss: 0.1734 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2610 - accuracy: 0.8875 - val_loss: 0.1915 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2634 - accuracy: 0.8875 - val_loss: 0.1692 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2621 - accuracy: 0.9125 - val_loss: 0.1637 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4e00e72978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 829
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gUhu0CQCmlb",
        "colab_type": "code",
        "outputId": "a9b69cfb-7af8-4e6f-d358-f7c4ed80debf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#test_loss, test_acc = network.evaluate(test_data, test_labels)\n",
        "\n",
        "accuracy, loss = network.evaluate(test_data, test_labels, verbose=2)"
      ],
      "execution_count": 830,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 - 0s - loss: 0.1804 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36-6KzagxxNY",
        "colab_type": "text"
      },
      "source": [
        "Function for plotting results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJiWFB5ScEQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display_all_data(labels, data, w, b):\n",
        "  ## Start by displaying the original scatter plot\n",
        "  for l, d in zip(labels, data):\n",
        "    if(l):\n",
        "      plt.plot(d[0], d[1], \"r.\")\n",
        "    else:\n",
        "      plt.plot(d[0], d[1], \"b.\")\n",
        "\n",
        "  ## Create an array of values from 0.0 - 1.0 to use when constructing lines\n",
        "  x = np.array(np.arange(0, 1.1, 0.1))\n",
        "\n",
        "  ## Display the expected line\n",
        "  y = w * x + b\n",
        "  plt.plot(x, y, 'c')  \n",
        "\n",
        "  ## Extract weights and biases from the network\n",
        "  w = network.layers[0].get_weights()[0]\n",
        "  b = network.layers[0].get_weights()[1]\n",
        "\n",
        "  ## Display the model's derived line (This does not appear fully correct, can't\n",
        "  ## tell if that's an issue with my model or my formula)\n",
        "  ## Since w1 x1 + w2 x2 + b = 0, x_2 = -(w1 * x1 + b) / w2 \n",
        "  y = -1 * (w[0] * x + b) / w[1]\n",
        "  plt.plot(x, y, 'm')\n",
        "\n",
        "  plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "  plt.ylabel(\"$x_2$\", rotation=0, fontsize=18)\n",
        "  plt.axis([0, 1, -15, 15])\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzva0pKqx6Jm",
        "colab_type": "text"
      },
      "source": [
        "Displays original scatter plot of the random data, as well as the true,\n",
        "expected line dividing this data (in blue) and the line keras derived (in magenta).\n",
        "\n",
        "The derived line is generally quite a bit off from where it should be, indicating that something in my model setup is incorrect, but frankly I was not able to find many resources actually helping me self-teach meaningfully *modeling* logistic regression in Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUF8Piqpdgmn",
        "colab_type": "code",
        "outputId": "631bce7d-946d-4ce8-c754-a3c28276e9f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "source": [
        "display_all_data(labels, data, w, b)"
      ],
      "execution_count": 832,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAESCAYAAAAFYll6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tioeZClUZC8d",
        "colab_type": "text"
      },
      "source": [
        "Print a heatmap of the function (Was not able to do this correctly, ran out of time to get my arrays in a form where they could be heatmapped)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-FnaFUE78-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import seaborn as sns\n",
        "#import random\n",
        "\n",
        "#heat_input = np.linspace((0,0),(1,1),100)\n",
        "#print(heat_input)\n",
        "\n",
        "#heat_output = np.empty((100, 100))\n",
        "\n",
        "#heat_output = network.predict(heat_input)\n",
        "\n",
        "#single_output = network.predict(3, 4)\n",
        "\n",
        "#print(heat_output.shape)\n",
        "#print(heat_output)\n",
        "\n",
        "#mappable_array = np.empty((100, 100))\n",
        "\n",
        "#for x in range(99):\n",
        "  #for y in range(99):\n",
        "    #mappable_array[x][y] = \n",
        "\n",
        "\n",
        "#plt.imshow(heat_output, cmap='hot', interpolation='nearest')\n",
        "#plt.show()\n",
        "\n",
        "#ax = sns.heatmap(heat_array, linewidth=0.01)\n",
        "#plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8KbbJ7vS0Ts",
        "colab_type": "text"
      },
      "source": [
        "# Problem 3 ~~ ***UNFINISHED***\n",
        "Use numpy to implement a logistic regression model from scratch and train it with the data generated as in Problem 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXUVbw-ooywf",
        "colab_type": "text"
      },
      "source": [
        "The following expression is the output of the neuron when given a feature vector $x=(x_1,\\ldots,x_n)^T\\in R^n$, represented in this code as the data numpy array, as input.\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{y} = a\\left( \\sum_{j=1}^n w_j x_j + b \\right)\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcEU90mWS6pm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Begin with the sum\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPXqWtg7rLmL",
        "colab_type": "text"
      },
      "source": [
        "Performing gradient descent - this is pulled directly from [linear_regression_gradient_descent.ipynb](https://colab.research.google.com/drive/1qBxfTPoNcSFvpwu1NDl1V6cHEqL3aQl-#scrollTo=QwrdvAfuiRaf), I was not able to make any changes or adjustments to it because I ran out of time, but I wanted to show where I would have started."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wknwnzw3rrv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of epochs\n",
        "epochs = 20\n",
        "# learning rate\n",
        "lr = 0.01\n",
        "# fix initial random weight for gradient descent\n",
        "initial_weight = np.random.randn(2, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwJUbkC0nHU2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "3954816a-e265-4a4a-839c-069d2391c312"
      },
      "source": [
        "weight = initial_weight\n",
        "weight_path_sgd = []\n",
        "\n",
        "# plot training data\n",
        "plt.plot(data, y, \"b.\")\n",
        "# plot initial prediction\n",
        "y_predict = X_new_b.dot(weight)                    \n",
        "plt.plot(X_new, y_predict, \"r--\")\n",
        "\n",
        "weight_path_sgd.append(weight)\n",
        "for epoch in range(epochs):\n",
        "    shuffled_indices = np.random.permutation(m)\n",
        "    X_b_shuffled = X_b[shuffled_indices]\n",
        "    y_shuffled = y[shuffled_indices]\n",
        "    \n",
        "    for i in range(m):\n",
        "        xi = X_b_shuffled[i:i+1]\n",
        "        yi = y_shuffled[i:i+1]\n",
        "        gradient = xi.T.dot(xi.dot(weight) - yi)\n",
        "        weight = weight - lr * gradient\n",
        "        weight_path_sgd.append(weight)\n",
        "        \n",
        "        y_predict = X_new_b.dot(weight)                    \n",
        "        plt.plot(X_new, y_predict, \"b-\")        \n",
        "    \n",
        "plt.xlabel(\"$x_1$\", fontsize=18)                     \n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)           \n",
        "plt.axis([0, 2, 0, 15])                                              \n",
        "plt.show()     "
      ],
      "execution_count": 634,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-634-00ad2a1f066b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# plot training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# plot initial prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_new_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    }
  ]
}